{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import tokenize\n",
    "import json\n",
    "import re\n",
    "file = 'RC_2016-02.bz2' \n",
    "bz_file = bz2.BZ2File(file, 'rb')\n",
    "c = 0\n",
    "token = TweetTokenizer()\n",
    "data = []\n",
    "#while c<=100000:\n",
    "#    c+=1\n",
    "#    line = bz_file.readline().decode('utf8')\n",
    "for rline in bz_file:\n",
    "    c+=1\n",
    "    if c>=100000:\n",
    "        break\n",
    "    line = rline.decode('utf8')\n",
    "    comment = json.loads(line)\n",
    "    body = comment[\"body\"]\n",
    "    commentLines = tokenize.sent_tokenize(body)\n",
    "    for line in commentLines:\n",
    "        s = re.sub(r'[\\.,\\?\\*!\\^-]','',line)\n",
    "        s = re.sub(r'NA|NAN','',s)\n",
    "        data.extend(token.tokenize(s))\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove common punctions\n",
    "tokenise the words using tweettokenizer to retain emoticons as they convey good amount of sentiments\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3268172\n",
      "['PEI', 'fully', 'funds', 'their', 'treatment', 'has', 'medical', 'abortions', 'in', 'province', 'and', 'will', 'pay', 'to', 'transport', 'patients', 'to', 'NB', 'for', 'surgical', 'abortions', 'Women', 'and', 'men', 'across', 'Canada', 'routinely', 'travel', 'equal', 'distances', 'to', 'access', 'care', 'I', 'love', 'Dubnyk', 'more', 'when', \"he's\", 'not', 'on', 'my', 'team', 'Oh', 'no', 'worries', 'just', 'wondering', 'since', 'I', 'live', 'near', 'oakland', 'MY', 'ACONDA', \"DON'T\", 'MY', 'ACONDA', \"DON'T\", '#MY', 'ACONDA', \"DON'T\", 'WANT', 'NONE', 'UNLESS', 'YOU', 'GUT', 'GRACE', 'NUN', 'Yay', 'verily', 'A', 'cookie', 'Precisely', '#BUFFYYYYYY', 'hi', 'i', 'sold', 'ft', 'redline', 'with', 'titan', 'nonholo', 'for', '9k', 'if', 'that', 'helps', ':)', 'The', 'Ballad', 'of', 'Sona', 'Lisa', 'how', 'lesbian', 'sex', 'works', 'the', 'fact']\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
